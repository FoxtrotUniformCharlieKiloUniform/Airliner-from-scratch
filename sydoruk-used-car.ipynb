{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c204df",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:16.731830Z",
     "iopub.status.busy": "2024-09-11T23:44:16.731332Z",
     "iopub.status.idle": "2024-09-11T23:44:23.589504Z",
     "shell.execute_reply": "2024-09-11T23:44:23.588720Z"
    },
    "papermill": {
     "duration": 6.867052,
     "end_time": "2024-09-11T23:44:23.591914",
     "exception": false,
     "start_time": "2024-09-11T23:44:16.724862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table names:  sample_submission.csv\n",
      "Table names:  train.csv\n",
      "Table names:  test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import preprocessing \n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(\"Table names: \", filename)\n",
    "        fullPath = os.path.join(dirname, filename)\n",
    "        \n",
    "        \n",
    "        if filename == \"train.csv\":\n",
    "            trainDS = pd.read_csv(fullPath)\n",
    "            trainDS = trainDS[1:1000]\n",
    "        if filename == \"test.csv\":\n",
    "            testDS = pd.read_csv(fullPath)\n",
    "        \n",
    "        \n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc745bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:23.602955Z",
     "iopub.status.busy": "2024-09-11T23:44:23.602576Z",
     "iopub.status.idle": "2024-09-11T23:44:23.720830Z",
     "shell.execute_reply": "2024-09-11T23:44:23.719847Z"
    },
    "papermill": {
     "duration": 0.125794,
     "end_time": "2024-09-11T23:44:23.722789",
     "exception": false,
     "start_time": "2024-09-11T23:44:23.596995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:  Tesla T4\n"
     ]
    }
   ],
   "source": [
    "## using hardware accelerators\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using GPU: \", torch.cuda.get_device_name(0))\n",
    "elif 'XLA_USE_BF16' in os.environ:  # This is how TPUs are usually detected in Kaggle\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    device = xm.xla_device()\n",
    "    print(\"Using TPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe086b37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:23.733991Z",
     "iopub.status.busy": "2024-09-11T23:44:23.733350Z",
     "iopub.status.idle": "2024-09-11T23:44:23.749273Z",
     "shell.execute_reply": "2024-09-11T23:44:23.748194Z"
    },
    "papermill": {
     "duration": 0.023633,
     "end_time": "2024-09-11T23:44:23.751291",
     "exception": false,
     "start_time": "2024-09-11T23:44:23.727658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    brand  model  model_year  milage fuel_type  \\\n",
      "1   1  Lincoln  LS V8        2002  143250  Gasoline   \n",
      "\n",
      "                                         engine transmission ext_col int_col  \\\n",
      "1  252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel          A/T  Silver   Beige   \n",
      "\n",
      "                                 accident clean_title  price  \n",
      "1  At least 1 accident or damage reported         Yes   4999  \n"
     ]
    }
   ],
   "source": [
    "## The plan\n",
    "#Split up engine type into the following columns\n",
    "#HP, engine size (without the Liter), cylinder number (sometimes says X cylinder, sometimes VX or IX),fuel type\n",
    "\n",
    "#encode brand, model, fuel_type, ext_col, int_col, accident, clean_title\n",
    "\n",
    "#label is obviously price\n",
    "print(trainDS.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22bbc4d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:23.762989Z",
     "iopub.status.busy": "2024-09-11T23:44:23.762051Z",
     "iopub.status.idle": "2024-09-11T23:44:23.769385Z",
     "shell.execute_reply": "2024-09-11T23:44:23.768573Z"
    },
    "papermill": {
     "duration": 0.01486,
     "end_time": "2024-09-11T23:44:23.771311",
     "exception": false,
     "start_time": "2024-09-11T23:44:23.756451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Data preprocessing block (from above plan)\\n#print(trainDS.head(20))\\nprint(trainDS[\"engine\"].value_counts())\\nprint(len(trainDS) - trainDS[\\'engine\\'].str.contains(\"HP\").sum())\\nprint(trainDS[\\'engine\\'].str.contains(\"HP\").sum())\\n\\nunique_non_occurrences = trainDS[~trainDS[\\'engine\\'].str.contains(\\'HP\\')][\\'engine\\'].unique()\\nprint(unique_non_occurrences)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking a look at what engines have HP in them or not\n",
    "'''## Data preprocessing block (from above plan)\n",
    "#print(trainDS.head(20))\n",
    "print(trainDS[\"engine\"].value_counts())\n",
    "print(len(trainDS) - trainDS['engine'].str.contains(\"HP\").sum())\n",
    "print(trainDS['engine'].str.contains(\"HP\").sum())\n",
    "\n",
    "unique_non_occurrences = trainDS[~trainDS['engine'].str.contains('HP')]['engine'].unique()\n",
    "print(unique_non_occurrences)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecee62ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:23.782318Z",
     "iopub.status.busy": "2024-09-11T23:44:23.782010Z",
     "iopub.status.idle": "2024-09-11T23:44:23.791779Z",
     "shell.execute_reply": "2024-09-11T23:44:23.790919Z"
    },
    "papermill": {
     "duration": 0.017581,
     "end_time": "2024-09-11T23:44:23.793701",
     "exception": false,
     "start_time": "2024-09-11T23:44:23.776120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # Ensure the input is a DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Variable is not a dataframe.\")\n",
    "        raise SystemExit(\"Stopping execution due to incorrect input.\")\n",
    "\n",
    "    # Check if 'engine' column exists\n",
    "    columnSet = [\"engine\"]\n",
    "    if set(columnSet).issubset(df.columns):\n",
    "        print(\"'engine' column found, processing...\")\n",
    "        \n",
    "        # Split the 'engine' column\n",
    "        try:\n",
    "            columnAdditions = df[\"engine\"].str.split('HP', expand=True)\n",
    "            intermVar = columnAdditions[1].str.split(\"L\", expand=True)\n",
    "            columnAdditions = pd.concat([columnAdditions, intermVar], axis=1)\n",
    "\n",
    "            # Cleanup column names\n",
    "            columnAdditions.columns = [0, 1, 2, 3]  # Give temporary names\n",
    "            columnAdditions = columnAdditions.rename(columns={0: \"HP\", 2: \"engine_size\"})\n",
    "            columnAdditions = columnAdditions.drop([1, 3], axis=1)  # Drop unnecessary columns\n",
    "\n",
    "            # Convert to numeric values\n",
    "            columnAdditions[\"HP\"] = pd.to_numeric(columnAdditions[\"HP\"], errors='coerce')\n",
    "            columnAdditions[\"engine_size\"] = pd.to_numeric(columnAdditions[\"engine_size\"], errors='coerce')\n",
    "\n",
    "            # Merge back with the original DataFrame\n",
    "            newdf = pd.concat([df, columnAdditions], axis=1)\n",
    "            newdf = newdf.drop(\"engine\", axis=1)  # Drop the original 'engine' column\n",
    "\n",
    "            print(\"Processing complete. Returning new DataFrame.\")\n",
    "            return newdf\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError: {e} - One of the expected columns is missing.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(\"'engine' column is not in the DataFrame (it might have already been processed).\")\n",
    "        return df  # Return the original DataFrame if no processing was done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f34e013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:23.804894Z",
     "iopub.status.busy": "2024-09-11T23:44:23.804574Z",
     "iopub.status.idle": "2024-09-11T23:44:23.810274Z",
     "shell.execute_reply": "2024-09-11T23:44:23.809531Z"
    },
    "papermill": {
     "duration": 0.013349,
     "end_time": "2024-09-11T23:44:23.812218",
     "exception": false,
     "start_time": "2024-09-11T23:44:23.798869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encodeData(df, columnSet):\n",
    "    #make sure ds is dataframe\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Variable is not dataframe\")\n",
    "        #raise SystemExit(\"Stop right there!\")\n",
    "       \n",
    "    #make sure column names are all valid \n",
    "    if set(columnSet).issubset(df.columns):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Col list invalid\")\n",
    "        #raise SystemExit(\"Stop right there!\")\n",
    "    \n",
    "    #encode all specified columns\n",
    "    for column in columnSet:\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade0f5fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:23.823198Z",
     "iopub.status.busy": "2024-09-11T23:44:23.822902Z",
     "iopub.status.idle": "2024-09-11T23:44:23.866556Z",
     "shell.execute_reply": "2024-09-11T23:44:23.865383Z"
    },
    "papermill": {
     "duration": 0.051469,
     "end_time": "2024-09-11T23:44:23.868608",
     "exception": false,
     "start_time": "2024-09-11T23:44:23.817139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'engine' column found, processing...\n",
      "Processing complete. Returning new DataFrame.\n"
     ]
    }
   ],
   "source": [
    "#load and process data\n",
    "batch_size = 32\n",
    "\n",
    "class carDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        #call engine preprocess method to preprocess the engines (split into HP and engine size)\n",
    "        self.df = preprocess(self.df)\n",
    "        self.df = encodeData(self.df, [\"model\", \"brand\", \"fuel_type\", \"transmission\", \"ext_col\", \"int_col\", \"accident\", \"clean_title\"])\n",
    "        \n",
    "        self.df = self.df.replace(np.nan,0)\n",
    "        \n",
    "        self.labels = self.df[[\"price\"]]   #y is just the price (this for )\n",
    "        self.labels=( self.labels- self.labels.min())/( self.labels.max()- self.labels.min())\n",
    "        \n",
    "        self.features = self.df.drop([\"price\"], axis = 1)  #x is dataframe with price column dropped \n",
    "        self.features = (self.features - self.features.mean())/self.features.std() \n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert the features and labels to PyTorch tensors\n",
    "        features_tensor = torch.tensor(self.features.iloc[idx], dtype=torch.float32).to(device)\n",
    "        labels_tensor = torch.tensor(self.labels.iloc[idx], dtype=torch.float32).to(device)\n",
    "        \n",
    "        return features_tensor, labels_tensor\n",
    " \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "carDataset = carDataset(trainDS)\n",
    "trainer = DataLoader(carDataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2a060bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:23.879651Z",
     "iopub.status.busy": "2024-09-11T23:44:23.879152Z",
     "iopub.status.idle": "2024-09-11T23:44:23.887562Z",
     "shell.execute_reply": "2024-09-11T23:44:23.886734Z"
    },
    "papermill": {
     "duration": 0.015981,
     "end_time": "2024-09-11T23:44:23.889387",
     "exception": false,
     "start_time": "2024-09-11T23:44:23.873406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load and process data\n",
    "batch_size = 32\n",
    "\n",
    "class carDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        #call engine preprocess method to preprocess the engines (split into HP and engine size)\n",
    "        self.df = preprocess(self.df)\n",
    "        self.df = encodeData(self.df, [\"model\", \"brand\", \"fuel_type\", \"transmission\", \"ext_col\", \"int_col\", \"accident\", \"clean_title\"])\n",
    "        \n",
    "        self.df = self.df.replace(np.nan,0)\n",
    "        \n",
    "        self.labels = self.df[[\"price\"]]   #y is just the price (this for )\n",
    "        self.features = self.df.drop([\"price\"], axis = 1)  #x is dataframe with price column dropped\n",
    "        print(self.features)\n",
    "        \n",
    "        self.features = (self.features - self.features.mean())/self.features.std() \n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert the features and labels to PyTorch tensors\n",
    "        features_tensor = torch.tensor(self.features.iloc[idx], dtype=torch.float32).to(device)\n",
    "        labels_tensor = torch.tensor(self.labels.iloc[idx], dtype=torch.float32).to(device)\n",
    "        \n",
    "        return features_tensor, labels_tensor\n",
    " \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7636e40a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:23.900239Z",
     "iopub.status.busy": "2024-09-11T23:44:23.899979Z",
     "iopub.status.idle": "2024-09-11T23:44:23.906379Z",
     "shell.execute_reply": "2024-09-11T23:44:23.905548Z"
    },
    "papermill": {
     "duration": 0.014105,
     "end_time": "2024-09-11T23:44:23.908295",
     "exception": false,
     "start_time": "2024-09-11T23:44:23.894190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#initial random trees \\n\\nimport ydf\\nlearner = ydf.GradientBoostedTreesLearner(\\n    num_trees=15,\\n    label=\"price\",\\n    min_examples = 3,\\n    random_seed = 1,\\n)\\n\\ntrainDS = encodeData(preprocess(trainDS), [\"model\", \"brand\", \"fuel_type\", \"transmission\", \"ext_col\", \"int_col\", \"accident\", \"clean_title\"])\\n#print(trainDS.head)\\nmodel = learner.train(trainDS)\\ntestDS = encodeData(preprocess(testDS), [\"model\", \"brand\", \"fuel_type\", \"transmission\", \"ext_col\", \"int_col\", \"accident\", \"clean_title\"])\\npredict = model.predict(testDS)\\nmodel.describe()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#initial random trees \n",
    "\n",
    "import ydf\n",
    "learner = ydf.GradientBoostedTreesLearner(\n",
    "    num_trees=15,\n",
    "    label=\"price\",\n",
    "    min_examples = 3,\n",
    "    random_seed = 1,\n",
    ")\n",
    "\n",
    "trainDS = encodeData(preprocess(trainDS), [\"model\", \"brand\", \"fuel_type\", \"transmission\", \"ext_col\", \"int_col\", \"accident\", \"clean_title\"])\n",
    "#print(trainDS.head)\n",
    "model = learner.train(trainDS)\n",
    "testDS = encodeData(preprocess(testDS), [\"model\", \"brand\", \"fuel_type\", \"transmission\", \"ext_col\", \"int_col\", \"accident\", \"clean_title\"])\n",
    "predict = model.predict(testDS)\n",
    "model.describe()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a68f935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:23.919229Z",
     "iopub.status.busy": "2024-09-11T23:44:23.918971Z",
     "iopub.status.idle": "2024-09-11T23:44:23.926110Z",
     "shell.execute_reply": "2024-09-11T23:44:23.925418Z"
    },
    "papermill": {
     "duration": 0.014846,
     "end_time": "2024-09-11T23:44:23.928083",
     "exception": false,
     "start_time": "2024-09-11T23:44:23.913237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65d3e60c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:23.939616Z",
     "iopub.status.busy": "2024-09-11T23:44:23.939291Z",
     "iopub.status.idle": "2024-09-11T23:44:28.698271Z",
     "shell.execute_reply": "2024-09-11T23:44:28.697412Z"
    },
    "papermill": {
     "duration": 4.76779,
     "end_time": "2024-09-11T23:44:28.700999",
     "exception": false,
     "start_time": "2024-09-11T23:44:23.933209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 45\n",
    "\n",
    "class usedCarModel(nn.Module):\n",
    "    def __init__(self, input_size, batch_size):\n",
    "        super(usedCarModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Define the layers\n",
    "        self.fc1 = nn.Linear(input_size, n*512)  # First hidden layer\n",
    "        self.bn1 = nn.BatchNorm1d(n*512)         # Batch Normalization for first hidden layer\n",
    "        self.fc2 = nn.Linear(n*512,n*256)        # Second hidden layer\n",
    "        self.bn2 = nn.BatchNorm1d(256*n)         # Batch Normalization for second hidden layer\n",
    "        self.fc3 = nn.Linear(256*n, 128*n)       # Third hidden layer\n",
    "        self.bn3 = nn.BatchNorm1d(128*n)         # Batch Normalization for third hidden layer\n",
    "        self.fc4 = nn.Linear(128*n, 64*n)        # Fourth hidden layer\n",
    "        self.fc5 = nn.Linear(64*n, 1)            # Output layer\n",
    "        \n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = x.to(device)\n",
    "        x = self.relu(self.bn1(self.fc1(x)))  # First layer + BatchNorm + activation\n",
    "        x = self.dropout(x)                   # Dropout layer\n",
    "        x = self.relu(self.bn2(self.fc2(x)))  # Second layer + BatchNorm + activation\n",
    "        x = self.dropout(x)                   # Dropout layer\n",
    "        x = self.relu(self.bn3(self.fc3(x)))  # Third layer + BatchNorm + activation\n",
    "        x = self.relu(self.fc4(x))            # Fourth layer + activation\n",
    "        x = self.fc5(x)                       # Output layer\n",
    "        return x\n",
    "\n",
    "\n",
    "#model / hyperparameter definitions\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0001\n",
    "input_size = trainDS.shape[1]\n",
    "model = usedCarModel(input_size, batch_size)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "lossVec = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "627f9559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:44:28.714638Z",
     "iopub.status.busy": "2024-09-11T23:44:28.713936Z",
     "iopub.status.idle": "2024-09-11T23:51:45.712989Z",
     "shell.execute_reply": "2024-09-11T23:51:45.711904Z"
    },
    "papermill": {
     "duration": 437.007964,
     "end_time": "2024-09-11T23:51:45.715161",
     "exception": false,
     "start_time": "2024-09-11T23:44:28.707197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4091963302.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  features_tensor = torch.tensor(self.features.iloc[idx], dtype=torch.float32).to(device)\n",
      "/tmp/ipykernel_23/4091963302.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  labels_tensor = torch.tensor(self.labels.iloc[idx], dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6328, learning rate 0.0001\n",
      "Mean epoch output:  [-0.03656581]\n",
      "Epoch [2/100], Loss: 0.0243, learning rate 0.0001\n",
      "Mean epoch output:  [-0.06918512]\n",
      "Epoch [3/100], Loss: 0.0221, learning rate 0.0001\n",
      "Mean epoch output:  [-0.03728673]\n",
      "Epoch [4/100], Loss: 0.0230, learning rate 0.0001\n",
      "Mean epoch output:  [0.00045303]\n",
      "Epoch [5/100], Loss: 0.0210, learning rate 0.0001\n",
      "Mean epoch output:  [0.067578]\n",
      "Epoch [6/100], Loss: 0.0198, learning rate 0.0001\n",
      "Mean epoch output:  [-0.0023343]\n",
      "Epoch [7/100], Loss: 0.0198, learning rate 0.0001\n",
      "Mean epoch output:  [0.03172849]\n",
      "Epoch [8/100], Loss: 0.0195, learning rate 0.0001\n",
      "Mean epoch output:  [0.03346122]\n",
      "Epoch [9/100], Loss: 0.0189, learning rate 0.0001\n",
      "Mean epoch output:  [-0.00072636]\n",
      "Epoch [10/100], Loss: 0.0177, learning rate 0.0001\n",
      "Mean epoch output:  [0.02897998]\n",
      "Epoch [11/100], Loss: 0.0176, learning rate 0.0001\n",
      "Mean epoch output:  [0.00616081]\n",
      "Epoch [12/100], Loss: 0.0182, learning rate 0.0001\n",
      "Mean epoch output:  [-0.01407771]\n",
      "Epoch [13/100], Loss: 0.0172, learning rate 0.0001\n",
      "Mean epoch output:  [0.02063939]\n",
      "Epoch [14/100], Loss: 0.0173, learning rate 0.0001\n",
      "Mean epoch output:  [-0.00385305]\n",
      "Epoch [15/100], Loss: 0.0157, learning rate 0.0001\n",
      "Mean epoch output:  [-0.06701178]\n",
      "Epoch [16/100], Loss: 0.0163, learning rate 0.0001\n",
      "Mean epoch output:  [-0.01561106]\n",
      "Epoch [17/100], Loss: 0.0148, learning rate 0.0001\n",
      "Mean epoch output:  [0.03661385]\n",
      "Epoch [18/100], Loss: 0.0154, learning rate 0.0001\n",
      "Mean epoch output:  [0.01442867]\n",
      "Epoch [19/100], Loss: 0.0143, learning rate 0.0001\n",
      "Mean epoch output:  [-0.05935738]\n",
      "Epoch [20/100], Loss: 0.0143, learning rate 0.0001\n",
      "Mean epoch output:  [-0.00543739]\n",
      "Epoch [21/100], Loss: 0.0145, learning rate 0.0001\n",
      "Mean epoch output:  [0.00873923]\n",
      "Epoch [22/100], Loss: 0.0135, learning rate 0.0001\n",
      "Mean epoch output:  [0.00724254]\n",
      "Epoch [23/100], Loss: 0.0134, learning rate 0.0001\n",
      "Mean epoch output:  [0.00810006]\n",
      "Epoch [24/100], Loss: 0.0135, learning rate 0.0001\n",
      "Mean epoch output:  [-0.02279833]\n",
      "Epoch [25/100], Loss: 0.0125, learning rate 0.0001\n",
      "Mean epoch output:  [-0.0685339]\n",
      "Epoch [26/100], Loss: 0.0121, learning rate 0.0001\n",
      "Mean epoch output:  [-0.05138575]\n",
      "Epoch [27/100], Loss: 0.0120, learning rate 0.0001\n",
      "Mean epoch output:  [0.07453955]\n",
      "Epoch [28/100], Loss: 0.0115, learning rate 0.0001\n",
      "Mean epoch output:  [0.03154467]\n",
      "Epoch [29/100], Loss: 0.0117, learning rate 0.0001\n",
      "Mean epoch output:  [-0.0375515]\n",
      "Epoch [30/100], Loss: 0.0112, learning rate 0.0001\n",
      "Mean epoch output:  [0.00710319]\n",
      "Epoch [31/100], Loss: 0.0106, learning rate 0.0001\n",
      "Mean epoch output:  [0.0124115]\n",
      "Epoch [32/100], Loss: 0.0112, learning rate 0.0001\n",
      "Mean epoch output:  [-0.06360155]\n",
      "Epoch [33/100], Loss: 0.0110, learning rate 0.0001\n",
      "Mean epoch output:  [0.05478983]\n",
      "Epoch [34/100], Loss: 0.0104, learning rate 0.0001\n",
      "Mean epoch output:  [0.05169342]\n",
      "Epoch [35/100], Loss: 0.0106, learning rate 0.0001\n",
      "Mean epoch output:  [-0.04174886]\n",
      "Epoch [36/100], Loss: 0.0110, learning rate 0.0001\n",
      "Mean epoch output:  [-0.05673093]\n",
      "Epoch [37/100], Loss: 0.0097, learning rate 0.0001\n",
      "Mean epoch output:  [-0.06026707]\n",
      "Epoch [38/100], Loss: 0.0102, learning rate 0.0001\n",
      "Mean epoch output:  [0.03033313]\n",
      "Epoch [39/100], Loss: 0.0097, learning rate 0.0001\n",
      "Mean epoch output:  [0.03026859]\n",
      "Epoch [40/100], Loss: 0.0100, learning rate 0.0001\n",
      "Mean epoch output:  [0.05218818]\n",
      "Epoch [41/100], Loss: 0.0096, learning rate 0.0001\n",
      "Mean epoch output:  [0.04798527]\n",
      "Epoch [42/100], Loss: 0.0097, learning rate 0.0001\n",
      "Mean epoch output:  [0.03900195]\n",
      "Epoch [43/100], Loss: 0.0091, learning rate 0.0001\n",
      "Mean epoch output:  [-0.00230211]\n",
      "Epoch [44/100], Loss: 0.0093, learning rate 0.0001\n",
      "Mean epoch output:  [0.04496938]\n",
      "Epoch [45/100], Loss: 0.0095, learning rate 0.0001\n",
      "Mean epoch output:  [0.03030323]\n",
      "Epoch [46/100], Loss: 0.0082, learning rate 0.0001\n",
      "Mean epoch output:  [0.03919899]\n",
      "Epoch [47/100], Loss: 0.0091, learning rate 0.0001\n",
      "Mean epoch output:  [-0.00796813]\n",
      "Epoch [48/100], Loss: 0.0093, learning rate 0.0001\n",
      "Mean epoch output:  [0.05924983]\n",
      "Epoch [49/100], Loss: 0.0086, learning rate 0.0001\n",
      "Mean epoch output:  [0.0364161]\n",
      "Epoch [50/100], Loss: 0.0085, learning rate 0.0001\n",
      "Mean epoch output:  [0.03625016]\n",
      "Epoch [51/100], Loss: 0.0089, learning rate 0.0001\n",
      "Mean epoch output:  [0.03992208]\n",
      "Epoch [52/100], Loss: 0.0088, learning rate 0.0001\n",
      "Mean epoch output:  [0.08102059]\n",
      "Epoch [53/100], Loss: 0.0088, learning rate 0.0001\n",
      "Mean epoch output:  [-0.01800036]\n",
      "Epoch [54/100], Loss: 0.0090, learning rate 0.0001\n",
      "Mean epoch output:  [-0.01792593]\n",
      "Epoch [55/100], Loss: 0.0076, learning rate 0.0001\n",
      "Mean epoch output:  [-0.02339277]\n",
      "Epoch [56/100], Loss: 0.0087, learning rate 0.0001\n",
      "Mean epoch output:  [-0.00559196]\n",
      "Epoch [57/100], Loss: 0.0077, learning rate 0.0001\n",
      "Mean epoch output:  [-0.03505944]\n",
      "Epoch [58/100], Loss: 0.0079, learning rate 0.0001\n",
      "Mean epoch output:  [-0.00899737]\n",
      "Epoch [59/100], Loss: 0.0078, learning rate 0.0001\n",
      "Mean epoch output:  [0.06720395]\n",
      "Epoch [60/100], Loss: 0.0082, learning rate 0.0001\n",
      "Mean epoch output:  [0.04828772]\n",
      "Epoch [61/100], Loss: 0.0081, learning rate 0.0001\n",
      "Mean epoch output:  [0.03623779]\n",
      "Epoch [62/100], Loss: 0.0077, learning rate 0.0001\n",
      "Mean epoch output:  [0.09239235]\n",
      "Epoch [63/100], Loss: 0.0080, learning rate 0.0001\n",
      "Mean epoch output:  [0.06206682]\n",
      "Epoch [64/100], Loss: 0.0084, learning rate 0.0001\n",
      "Mean epoch output:  [0.0172525]\n",
      "Epoch [65/100], Loss: 0.0075, learning rate 0.0001\n",
      "Mean epoch output:  [0.03387531]\n",
      "Epoch [66/100], Loss: 0.0073, learning rate 0.0001\n",
      "Mean epoch output:  [0.03095236]\n",
      "Epoch [67/100], Loss: 0.0078, learning rate 0.0001\n",
      "Mean epoch output:  [-0.04554809]\n",
      "Epoch [68/100], Loss: 0.0075, learning rate 0.0001\n",
      "Mean epoch output:  [0.08129393]\n",
      "Epoch [69/100], Loss: 0.0069, learning rate 0.0001\n",
      "Mean epoch output:  [0.04677369]\n",
      "Epoch [70/100], Loss: 0.0073, learning rate 0.0001\n",
      "Mean epoch output:  [0.00192525]\n",
      "Epoch [71/100], Loss: 0.0068, learning rate 0.0001\n",
      "Mean epoch output:  [0.02250843]\n",
      "Epoch [72/100], Loss: 0.0072, learning rate 0.0001\n",
      "Mean epoch output:  [0.04885947]\n",
      "Epoch [73/100], Loss: 0.0076, learning rate 0.0001\n",
      "Mean epoch output:  [0.00845653]\n",
      "Epoch [74/100], Loss: 0.0072, learning rate 0.0001\n",
      "Mean epoch output:  [-0.02286199]\n",
      "Epoch [75/100], Loss: 0.0070, learning rate 0.0001\n",
      "Mean epoch output:  [0.01042167]\n",
      "Epoch [76/100], Loss: 0.0072, learning rate 0.0001\n",
      "Mean epoch output:  [-0.01729691]\n",
      "Epoch [77/100], Loss: 0.0072, learning rate 0.0001\n",
      "Mean epoch output:  [0.02853467]\n",
      "Epoch [78/100], Loss: 0.0069, learning rate 0.0001\n",
      "Mean epoch output:  [0.05397502]\n",
      "Epoch [79/100], Loss: 0.0065, learning rate 0.0001\n",
      "Mean epoch output:  [-0.01290605]\n",
      "Epoch [80/100], Loss: 0.0069, learning rate 0.0001\n",
      "Mean epoch output:  [0.07505565]\n",
      "Epoch [81/100], Loss: 0.0074, learning rate 0.0001\n",
      "Mean epoch output:  [-0.06855624]\n",
      "Epoch [82/100], Loss: 0.0070, learning rate 0.0001\n",
      "Mean epoch output:  [-0.04063767]\n",
      "Epoch [83/100], Loss: 0.0065, learning rate 0.0001\n",
      "Mean epoch output:  [-0.02077419]\n",
      "Epoch [84/100], Loss: 0.0069, learning rate 0.0001\n",
      "Mean epoch output:  [0.0357733]\n",
      "Epoch [85/100], Loss: 0.0065, learning rate 0.0001\n",
      "Mean epoch output:  [0.02604495]\n",
      "Epoch [86/100], Loss: 0.0063, learning rate 0.0001\n",
      "Mean epoch output:  [0.06789828]\n",
      "Epoch [87/100], Loss: 0.0068, learning rate 0.0001\n",
      "Mean epoch output:  [-0.00053078]\n",
      "Epoch [88/100], Loss: 0.0066, learning rate 0.0001\n",
      "Mean epoch output:  [0.04159494]\n",
      "Epoch [89/100], Loss: 0.0063, learning rate 0.0001\n",
      "Mean epoch output:  [0.01754884]\n",
      "Epoch [90/100], Loss: 0.0086, learning rate 0.0001\n",
      "Mean epoch output:  [0.02777458]\n",
      "Epoch [91/100], Loss: 0.0065, learning rate 0.0001\n",
      "Mean epoch output:  [-0.00316553]\n",
      "Epoch [92/100], Loss: 0.0061, learning rate 0.0001\n",
      "Mean epoch output:  [0.0339838]\n",
      "Epoch [93/100], Loss: 0.0065, learning rate 0.0001\n",
      "Mean epoch output:  [0.05808079]\n",
      "Epoch [94/100], Loss: 0.0059, learning rate 0.0001\n",
      "Mean epoch output:  [0.03245342]\n",
      "Epoch [95/100], Loss: 0.0063, learning rate 0.0001\n",
      "Mean epoch output:  [-0.02951844]\n",
      "Epoch [96/100], Loss: 0.0060, learning rate 0.0001\n",
      "Mean epoch output:  [-0.00401087]\n",
      "Epoch [97/100], Loss: 0.0064, learning rate 0.0001\n",
      "Mean epoch output:  [-0.00694372]\n",
      "Epoch [98/100], Loss: 0.0057, learning rate 0.0001\n",
      "Mean epoch output:  [0.01868681]\n",
      "Epoch [99/100], Loss: 0.0060, learning rate 0.0001\n",
      "Mean epoch output:  [0.03274706]\n",
      "Epoch [100/100], Loss: 0.0064, learning rate 0.0001\n",
      "Mean epoch output:  [-0.02699394]\n"
     ]
    }
   ],
   "source": [
    "#Reduce LR Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor = 0.7, patience = 2)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    total_output = []\n",
    "    \n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(trainer):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        total_mae = 0.0\n",
    "        outputs = model(inputs).to(device)\n",
    "        \n",
    "        #print(\"Average label: \", sum(labels)/len(labels), \"average output: \",sum(outputs)/len(outputs))\n",
    "       \n",
    "        total_output.append(outputs.cpu().detach().numpy())\n",
    "        \n",
    "        loss = criterion(outputs, labels.float())\n",
    "                         \n",
    "        # Backward pass and optimization\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        scheduler.step(running_loss)\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate precision and accuracy\n",
    "        # Calculate MAE for this batch\n",
    "        batch_mae = torch.mean(torch.abs(outputs - labels)).item()\n",
    "        total_mae += batch_mae\n",
    "        \n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    epoch_loss = running_loss / len(trainer)\n",
    "    lossVec[epoch] = epoch_loss\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, learning rate {learning_rate}')\n",
    "    \n",
    "    mean_epoch_output = sum(outputs.cpu().detach().numpy()) / len(outputs.cpu().detach().numpy())\n",
    "    print(\"Mean epoch output: \",mean_epoch_output)\n",
    "    \n",
    "total_output = np.concatenate(total_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d141ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T23:51:45.742485Z",
     "iopub.status.busy": "2024-09-11T23:51:45.742160Z",
     "iopub.status.idle": "2024-09-11T23:51:46.015858Z",
     "shell.execute_reply": "2024-09-11T23:51:46.014778Z"
    },
    "papermill": {
     "duration": 0.2896,
     "end_time": "2024-09-11T23:51:46.017832",
     "exception": false,
     "start_time": "2024-09-11T23:51:45.728232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1d6e79f5b0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "import matplotlib.pyplot as plt\n",
    "epochVec = np.arange(1,num_epochs+1)\n",
    "\n",
    "plt.plot(epochVec, lossVec,'o-')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9057646,
     "sourceId": 76728,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 453.545655,
   "end_time": "2024-09-11T23:51:47.453222",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-11T23:44:13.907567",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
